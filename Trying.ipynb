{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48499dd0-46cb-43e3-bb5c-fd7c9dde0bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "pdf_path = \"Documents/trial_1/CBSE_10.pdf\"\n",
    "images = convert_from_path(pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04a8c391-4c19-446c-847d-d25d3ddf3ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f\"Documents/trial_1/my_file{d}.txt\"\n",
    "def answer_key(result,file_path):\n",
    "    for i in result:\n",
    "        pages = \"\"\n",
    "        for j in i:\n",
    "            pages=pages + j[-2]\n",
    "        ref = get_refined(pages)\n",
    "        with open(file_path, \"a\") as file:\n",
    "            file.write(ref)\n",
    "    return file_path\n",
    "        \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1ee720b-46a0-4a0b-8bf5-12d32ae478f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "written_on= answer_key(result,file_path)\n",
    "\n",
    "with open(written_on, 'r') as file:\n",
    "    file_contents = file.read()\n",
    "      # Process file_contents\n",
    "    # File is automatically closed outside the 'with' block\n",
    "print(file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8acc6bfd-a3af-4dde-a847-95c63ec769a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Documents/trial_1/my_file2.txt'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3e359e9f-3bd6-4009-bca6-4707ed73ed9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your raw ocr text here...\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    import re\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\n+', ' ', text)  # Replace multiple newlines with space\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Remove URLs\n",
    "   # text = re.sub(r'[^a-zA-Z0-9.,;?!\\s]', '', text)  # Remove special characters\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d12940d7-ab5f-402c-a847-0fe6bb173011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def qna(text):\n",
    "    \n",
    "    question_patterns = [\n",
    "        r\"^\\d+\\s*[\\.\\):-]?\\s*explain.*\",\n",
    "        r\"^\\d+\\s*[\\.\\):-]?\\s*compare.*\",\n",
    "        r\"^\\d+\\s*[\\.\\):-]?\\s*differentiate.*\",\n",
    "        r\"^\\d+\\s*[\\.\\):-]?\\s*answer the following.*\",\n",
    "        r\"^\\d+\\s*[\\.\\):-]?\\s*find.*\",\n",
    "        r\"^\\d+\\s*[\\.\\):-]?\\s*why.*\",\n",
    "        r\"^\\d+\\s*[\\.\\):-]?\\s*how.*\",\n",
    "        r\"^\\d+\\s*[\\.\\):-]?\\s*when.*\",\n",
    "        r\"^\\d+\\s*[\\.\\):-]?\\s*where.*\",\n",
    "        r\"^\\d+\\s*[\\.\\):-]?\\s*who.*\",\n",
    "        r\"^\\d+\\s*[\\.\\):-]?\\s*what.*\",\n",
    "        r\"^explain.*\",\n",
    "        r\"^compare.*\",\n",
    "        r\"^differentiate.*\",\n",
    "        r\"^answer the following.*\",\n",
    "        r\"^find.*\",\n",
    "        r\"^why.*\",\n",
    "        r\"^how.*\",\n",
    "        r\"^when.*\",\n",
    "        r\"^where.*\",\n",
    "        r\"^who.*\",\n",
    "        r\"^what.*\"\n",
    "    ]\n",
    "\n",
    "    answer_patterns = [\n",
    "        r\"^ans.*\",\n",
    "        r\"^sol.*\",\n",
    "        r\"^\\d+\\s*[\\.\\):-]?\\s*ans.*\",\n",
    "        r\"^\\d+\\s*[\\.\\):-]?\\s*sol.*\"\n",
    "    ]\n",
    "\n",
    "    sentences = []\n",
    "    qflag = 0\n",
    "    aflag = 0\n",
    "    q = \"\"\n",
    "    a = \"\"\n",
    "\n",
    "    for w in text:\n",
    "        w = w.strip()\n",
    "        w = w.lower()\n",
    "        w = clean_text(w)\n",
    "        # Detect question\n",
    "        if any(re.match(pattern, w, re.IGNORECASE) for pattern in question_patterns):\n",
    "            if aflag == 1:\n",
    "                sentences.append(a.strip() + \"\\n\")\n",
    "                a = \"\"\n",
    "\n",
    "            # If another question comes consecutively, merge it\n",
    "            if qflag == 1:\n",
    "                q += \" \" + w  # Append to the previous question\n",
    "            else:\n",
    "                if q:  # If a previous question exists, store it first\n",
    "                    sentences.append(q.strip() + \"\\n\")\n",
    "                q = w  # Start a new question\n",
    "                qflag = 1\n",
    "            aflag = 0\n",
    "\n",
    "        # Detect answer\n",
    "        elif any(re.match(pattern, w, re.IGNORECASE) for pattern in answer_patterns):\n",
    "            if qflag == 1:\n",
    "                sentences.append(q.strip() + \"\\n\")\n",
    "                q = \"\"\n",
    "            a = w\n",
    "            aflag = 1\n",
    "            qflag = 0\n",
    "\n",
    "        # Continue previous question/answer\n",
    "        else:\n",
    "            if qflag == 1:\n",
    "                q += \" \" + w\n",
    "            elif aflag == 1:\n",
    "                a += \" \" + w\n",
    "\n",
    "    # Append last question/answer\n",
    "    if q:\n",
    "        sentences.append(q.strip() + \"\\n\")\n",
    "    if a:\n",
    "        sentences.append(a.strip() + \"\\n\")\n",
    "\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a4f38d69-86e3-4895-875b-40ad7b9ebff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f\"Documents/trial_1/my_file{d}.txt\"\n",
    "def answer_key(sentences,file_path):\n",
    "    with open(file_path, \"a\") as file:\n",
    "        for i in sentences:\n",
    "            file.write(i)\n",
    "            file.write(\"*\" *10)\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b74cdb83-ca08-450d-8504-196aefe8f4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_teacher(pdf_path,id):\n",
    "    import easyocr\n",
    "    from pdf2image import convert_from_path\n",
    "    images = convert_from_path(pdf_path)\n",
    "    reader = easyocr.Reader(['en'])  # 'en' is for English\n",
    "    result = []\n",
    "    for i, image in enumerate(images):\n",
    "        image.save(f\"output_image_{i}.jpg\", \"JPEG\")\n",
    "        r=reader.readtext(f\"output_image_{i}.jpg\",detail=1)\n",
    "        result.append(r)\n",
    "    phrases =[]\n",
    "    for i in result:\n",
    "        for j in i:\n",
    "            phrases.append( j[-2])\n",
    "            #print(j[-2])\n",
    "    sentences = qna(phrases)\n",
    "    file_path = f\"Documents/trial_1/teacher{id}.txt\"\n",
    "    written_in = answer_key(sentences,file_path)\n",
    "    print(\"open this path to recheck for changes: \",written_in)\n",
    "    return written_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8731f010-ecd1-4499-b2ec-ef74871f8637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_student(pdf_path,roll):\n",
    "    import easyocr\n",
    "    from pdf2image import convert_from_path\n",
    "    images = convert_from_path(pdf_path)\n",
    "    reader = easyocr.Reader(['en'])  # 'en' is for English\n",
    "    result = []\n",
    "    for i, image in enumerate(images):\n",
    "        image.save(f\"output_image_{i}.jpg\", \"JPEG\")\n",
    "        r=reader.readtext(f\"output_image_{i}.jpg\",detail=1)\n",
    "        result.append(r)\n",
    "    phrases =[]\n",
    "    for i in result:\n",
    "        for j in i:\n",
    "            phrases.append( j[-2])\n",
    "            #print(j[-2])\n",
    "    sentences = qna(phrases)\n",
    "    file_path = f\"Documents/trial_1/student{roll}.txt\"\n",
    "    written_in = answer_key(sentences,file_path)\n",
    "    print(\"open this path to recheck for changes: \",written_in)\n",
    "    return written_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "dd4f2270-cd0f-4c36-a7fb-51c0f48b4b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(9817) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(9819) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(9820) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "/opt/anaconda3/envs/example/lib/python3.12/site-packages/easyocr/detection.py:85: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "/opt/anaconda3/envs/example/lib/python3.12/site-packages/easyocr/recognition.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open this path:  Documents/trial_1/my_file4.txt\n"
     ]
    }
   ],
   "source": [
    "teacher = \"Documents/trial_1/CBSE_10.pdf\"\n",
    "student = \"student's_file_path\"\n",
    "roll = \"rollno. of student\"\n",
    "teacher= note_teacher(teacher) # this function is for noting down the answer_key or student's copy\n",
    "student  = note_student(student, roll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "754d692f-9473-4fb2-af81-24c3111158a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/example/lib/python3.12/site-packages/easyocr/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "print(easyocr.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f094938-ce44-40dd-8f59-74b1f92cbc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_response(prompt):\n",
    "    stored_response=\"\"\n",
    "    \"\"\"Sends a prompt to the Groq API and returns the response as a string.\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama-3.3-70b-versatile\",  # Choose model (like llama3-8b)\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "       temperature=1,\n",
    "    max_completion_tokens=1024,\n",
    "    top_p=1,\n",
    "    stream=True,\n",
    "    stop=None,\n",
    "    )\n",
    "    for chunk in response:\n",
    "        if chunk.choices[0].delta.content is None:\n",
    "            stored_response += \"\"\n",
    "        else:\n",
    "            stored_response += (chunk.choices[0].delta.content or \"\")\n",
    "    return stored_response\n",
    "\n",
    "\n",
    "# Example usage\n",
    "user_input = \"Explain quantum computing in simple terms.\"\n",
    "llm_response = get_llm_response(user_input)\n",
    "\n",
    "# Store response in a variable\n",
    "#stored_response = str(llm_response)\n",
    "\n",
    "print(\"LLM Response:\", llm_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b2a616e9-7e3b-4e4b-83bb-2b6354231fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qna(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        content= file.read()\n",
    "        sent = content.split(\"*\"*10)\n",
    "    x= 0\n",
    "    ans= []\n",
    "    ques= []\n",
    "    for i in sent:\n",
    "        if x%2==0:\n",
    "            ques.append(i)\n",
    "        else:\n",
    "            ans.append(i)\n",
    "        x=x+1\n",
    "    return ques,ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "478b5140-10e1-4e4a-bbc9-fcff72dcdeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_file(teacher,student,path):\n",
    "    \n",
    "    import pandas as pd\n",
    "    q, ans_key = get_qna(teacher)\n",
    "    q, ans_stu = get_qna(student)\n",
    "    max_marks = []\n",
    "    print(\"Enterprint max marks of each question: \")\n",
    "    for i in range(len(ans_key)):\n",
    "        x=0\n",
    "        x = int(input(\"enter the max marks of question \",(i+1)))\n",
    "        max_marks.append(x)\n",
    "    \n",
    "    # Create a dictionary where keys are column names and values are the column lists\n",
    "    data = {'Question': q, 'Answer_key': ans_key, 'Student_answer': ans_stu,'Max_Marks':max_marks}\n",
    "\n",
    "    # Create a Pandas DataFrame from the dictionary\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Write the DataFrame to a CSV file\n",
    "    df.to_csv(path, index=True) \n",
    "\n",
    "    print(f\"CSV file {path} created successfully.\")\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "cf06eaf0-a850-4b2b-9b76-e7fff0a69edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "import os\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "def get_llm_response(prompt):\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    stored_response = \"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"llama-3.3-70b-versatile\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=1,\n",
    "        max_completion_tokens=1024,\n",
    "        top_p=1,\n",
    "        stream=True,\n",
    "        stop=None,\n",
    "    )\n",
    "    for chunk in response:\n",
    "        if chunk.choices[0].delta.content is None:\n",
    "            stored_response += \"\"\n",
    "        else:\n",
    "            stored_response += (chunk.choices[0].delta.content or \"\")\n",
    "    return stored_response\n",
    "\n",
    "#csv_path  = get_csv_file(path)\n",
    "\n",
    "def evaluate(csv_path):\n",
    "    # Load CSV file\n",
    "    df = pd.read_csv(\"evaluation_data.csv\")\n",
    "    # Convert each row to JSON format and send it as a prompt\n",
    "    for _, row in df.iterrows():\n",
    "        data = {\n",
    "        \"question\": row[\"Question\"],\n",
    "        \"teacher_answer\": row[\"Teacher's Answer\"],\n",
    "        \"student_answer\": row[\"Student's Answer\"],\n",
    "        \"max_marks\": row[\"Max Marks\"]\n",
    "        }\n",
    "        # Convert dict to JSON string\n",
    "        json_prompt = json.dumps(data, indent=4)\n",
    "    \n",
    "        # Construct the LLM prompt\n",
    "    prompt = f\"\"\"\n",
    "    Here are multiple question, answer key and student's answer sets with max marks.\n",
    "    {json_prompt}\n",
    "    \n",
    "    For each question, compare the student's answer with the teacher's answer. Identify missing key points and provide a \n",
    "    tabular output with the marks awarded.\n",
    "    \"\"\"\n",
    "        \n",
    "    # Get response from LLM\n",
    "    \n",
    "    response = get_llm_response(prompt)\n",
    "    print(response) \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5873ec2-28a3-4fae-a70f-5a58cca88c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
